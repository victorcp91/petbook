name: Pull Request Tests

on:
  pull_request:
    branches: [main, develop]
  pull_request_target:
    branches: [main, develop]

env:
  NODE_VERSION: '18'

jobs:
  # Code Quality Checks
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

      - name: Run Prettier check
        run: npm run format:check

      - name: Run TypeScript check
        run: npm run type-check

      - name: Check for security vulnerabilities
        run: npm audit --audit-level=moderate

      - name: Upload code quality results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: code-quality-results
          path: |
            eslint-report.json
            prettier-report.json
            audit-report.json

  # Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests
        run: npm run test:unit -- --coverage --watchAll=false

      - name: Run integration tests
        run: npm run test:integration -- --coverage --watchAll=false

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: unit-tests-coverage

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: |
            coverage/
            test-results/
            *.xml

  # E2E Tests
  e2e-tests:
    name: E2E Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup Cypress cache
        uses: cypress-io/github-action@v6
        with:
          install-command: npm ci
          wait-on: 'http://localhost:3000'
          wait-on-timeout: 120

      - name: Start development server
        run: npm run dev &

      - name: Run E2E tests
        uses: cypress-io/github-action@v6
        with:
          browser: chrome
          headed: false
          record: false
          parallel: false
          group: 'E2E Tests'
          spec: 'cypress/e2e/**/*.cy.ts'
          config-file: cypress.config.ts
          env: |
            CI=true
            coverage=false

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            cypress/videos/
            cypress/screenshots/
            cypress/results/

  # Visual Regression Tests
  visual-regression:
    name: Visual Regression
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Setup Cypress cache
        uses: cypress-io/github-action@v6
        with:
          install-command: npm ci
          wait-on: 'http://localhost:3000'
          wait-on-timeout: 120

      - name: Start development server
        run: npm run dev &

      - name: Run visual regression tests
        uses: cypress-io/github-action@v6
        with:
          browser: chrome
          headed: false
          record: false
          parallel: false
          group: 'Visual Regression Tests'
          spec: 'cypress/e2e/visual-regression.cy.ts'
          config-file: cypress.config.ts
          env: |
            CI=true
            visualRegressionType=regression
            visualRegressionThreshold=0.1

      - name: Upload visual regression results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: visual-regression-results
          path: |
            cypress/visual-regression/
            cypress/videos/
            cypress/screenshots/

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Start development server
        run: npm run dev &

      - name: Wait for server
        run: npx wait-on http://localhost:3000

      - name: Run Lighthouse CI
        run: npx lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-results
          path: .lighthouseci/

  # Build Check
  build-check:
    name: Build Check
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: build-check-results
          path: |
            .next/
            out/

  # Test Summary and PR Comment
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs:
      [
        code-quality,
        unit-tests,
        e2e-tests,
        visual-regression,
        performance-tests,
        build-check,
      ]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download test artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-artifacts

      - name: Generate test summary
        run: |
          echo "## 🧪 Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Code Quality" >> $GITHUB_STEP_SUMMARY
          echo "- **ESLint**: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Prettier**: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **TypeScript**: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Audit**: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🧪 Unit & Integration Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage**: Available in Codecov" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🌐 E2E Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Specs**: All E2E test suites" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🎨 Visual Regression Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ needs.visual-regression.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage**: UI components and pages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ⚡ Performance Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tool**: Lighthouse CI" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🔨 Build Check" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ needs.build-check.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment**: Production build" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📈 Overall Status" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ needs.code-quality.result }}" == "success" && "${{ needs.unit-tests.result }}" == "success" && "${{ needs.e2e-tests.result }}" == "success" && "${{ needs.visual-regression.result }}" == "success" && "${{ needs.performance-tests.result }}" == "success" && "${{ needs.build-check.result }}" == "success" ]]; then
            echo "✅ **All tests passed!** Ready for review and merge." >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Some tests failed.** Please review the results above." >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📋 Next Steps" >> $GITHUB_STEP_SUMMARY
          echo "- Review test results and artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- Address any failing tests" >> $GITHUB_STEP_SUMMARY
          echo "- Update visual regression baselines if needed" >> $GITHUB_STEP_SUMMARY
          echo "- Request review from team members" >> $GITHUB_STEP_SUMMARY

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync(process.env.GITHUB_STEP_SUMMARY, 'utf8');

            // Create detailed comment with test results
            const comment = `${summary}

            ### 📁 Test Artifacts
            - **Unit Test Results**: Available in workflow artifacts
            - **E2E Test Videos**: Available in workflow artifacts
            - **Visual Regression Screenshots**: Available in workflow artifacts
            - **Performance Reports**: Available in workflow artifacts

            ### 🔍 How to Review
            1. Check the status of each test category above
            2. Download artifacts to review detailed results
            3. Address any failing tests before merging
            4. Update visual regression baselines if UI changes are intentional

            ### 🚀 Ready to Merge?
            All tests must pass before this PR can be merged.`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  # Status Check
  status-check:
    name: Status Check
    runs-on: ubuntu-latest
    needs:
      [
        code-quality,
        unit-tests,
        e2e-tests,
        visual-regression,
        performance-tests,
        build-check,
      ]

    steps:
      - name: Check all tests passed
        run: |
          if [[ "${{ needs.code-quality.result }}" == "success" && "${{ needs.unit-tests.result }}" == "success" && "${{ needs.e2e-tests.result }}" == "success" && "${{ needs.visual-regression.result }}" == "success" && "${{ needs.performance-tests.result }}" == "success" && "${{ needs.build-check.result }}" == "success" ]]; then
            echo "✅ All tests passed!"
            exit 0
          else
            echo "❌ Some tests failed!"
            exit 1
          fi
